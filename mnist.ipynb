{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import vdrvc \n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import reader\n",
    "from theano import tensor as T\n",
    "from sklearn.datasets import load_digits\n",
    "from IPython.display import clear_output as cls\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(\"ignore\")\n",
    "np.random.seed(15632)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, t_train, X_test, t_test, _, _ = reader.load_mnist()[0]\n",
    "X_train, X_test = X_train.reshape(len(X_train), -1), X_test.reshape(len(X_test), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 0 vlb = 1295159.0781 acc = 0.1145 ard = 0.1056\n",
      "iter = 1000 vlb = 36276.4532 acc = 0.9264 ard = 0.2341\n",
      "iter = 2000 vlb = 20395.7240 acc = 0.9342 ard = 0.2976\n",
      "iter = 3000 vlb = 15236.5419 acc = 0.9348 ard = 0.3638\n",
      "iter = 4000 vlb = 13622.8063 acc = 0.9341 ard = 0.4071\n",
      "iter = 5000 vlb = 12913.4083 acc = 0.9342 ard = 0.4557\n",
      "iter = 6000 vlb = 12584.1452 acc = 0.9340 ard = 0.4962\n",
      "iter = 7000 vlb = 12297.6962 acc = 0.9339 ard = 0.5460\n",
      "iter = 8000 vlb = 12273.3160 acc = 0.9340 ard = 0.5828\n",
      "iter = 9000 vlb = 12172.8914 acc = 0.9339 ard = 0.6110\n",
      "iter = 10000 vlb = 12165.3529 acc = 0.9340 ard = 0.6431\n",
      "iter = 11000 vlb = 12071.5542 acc = 0.9339 ard = 0.6666\n",
      "iter = 12000 vlb = 12030.7657 acc = 0.9341 ard = 0.6710\n",
      "iter = 13000 vlb = 12044.9001 acc = 0.9339 ard = 0.6823\n",
      "iter = 14000 vlb = 12015.5507 acc = 0.9340 ard = 0.6976\n"
     ]
    }
   ],
   "source": [
    "vd = vdrvc.vdrvc()\n",
    "vd = vd.fit(X_train, t_train, num_classes=10, batch_size=X_train.shape[0],\n",
    "            max_iter=15000, lr=1e-2, beta=0.9, display_each=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity = 0.6976\n",
      "train = 0.9339\n",
      "test = 0.9260\n"
     ]
    }
   ],
   "source": [
    "# Remove features with dropout rate p > 0.99 ~ log_alpha > 5\n",
    "ard = np.sum(vd.log_alpha > 5)\n",
    "vd.theta_old = vd.theta.copy()\n",
    "vd.theta[vd.log_alpha > 5] = 0\n",
    "# Accuracy score\n",
    "trainp, testp = acc(vd.predict(X_train), t_train), acc(vd.predict(X_test), t_test) \n",
    "print('sparsity = %0.4f' % (ard * 1.0 / vd.theta.size))\n",
    "print('train = %0.4f' % trainp)\n",
    "print('test = %0.4f' % testp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV as LR\n",
    "\n",
    "lr = LR(penalty='l1', verbose=3, solver='liblinear').fit(X_train, t_train)\n",
    "cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity = 0.5781\n",
      "train = 0.9259\n",
      "test = 0.9185\n"
     ]
    }
   ],
   "source": [
    "ard = np.sum(lr.coef_ == 0)\n",
    "trainp, testp = acc(lr.predict(X_train), t_train), acc(lr.predict(X_test), t_test) \n",
    "print('sparsity = %0.4f' % (ard * 1.0 / lr.coef_.size))\n",
    "print('train = %0.4f' % trainp)\n",
    "print('test = %0.4f' % testp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanila RVM (does not work on MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from skbayes.rvm_ard_models.fast_rvm import ClassificationARD\n",
    "# https://github.com/AmazaspShumik/sklearn-bayes"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
